{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "107841cb-5fd9-41a1-9e16-1559ffd13a87",
   "metadata": {},
   "source": [
    "# Running the 'data to document' step of the pdf2text pipeline\n",
    "\n",
    "This notebook contains code which processes a folder of intermediate outputs (i.e. folders direct from Adobe Extract or files from pdfalto) into `Document` objects, and saves .json and .txt files to a specified folder.\n",
    "\n",
    "It's left as a notebook for now, in order to enable experimentation with development of pipeline elements and not make premature decisions about implementation in the product pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f31ddc47-6ea8-4bc3-8b11-b58b8dd23551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from extract.extract import DocumentEmbeddedTextExtractor, AdobeAPIExtractor\n",
    "from extract.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ad29c5c-3545-4e51-8bb3-f16ff3107c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERMEDIATE_FOLDER = Path(\"../../../data/pdf2text/intermediate-final/\")\n",
    "OUTPUT_FOLDER = Path(\"../../../data/pdf2text/output-final-220424/\")\n",
    "\n",
    "PDFALTO_PATH = Path(\"../../../misc/pdfalto/pdfalto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7ab7b7f-f204-4ad6-8792-8d3fd244fbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_extractor = DocumentEmbeddedTextExtractor(pdfalto_path=PDFALTO_PATH)\n",
    "adobe_extractor = AdobeAPIExtractor(credentials_path=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1db5da02-6e0a-4938-b873-ad533f605b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: it could be useful to restructure the intermediate directory so each PDF parsed has its own folder, rather than many folders or XML files\n",
    "# To do this we'd have to modify pdf2text, but this is probably better done after the merge.\n",
    "# For now we identify folders and files belonging to each PDF using the method below\n",
    "\n",
    "def group_intermediate_dir_by_pdf():\n",
    "    \"\"\"\n",
    "    This assumes a flat structure for the intermediate dir, containing both Adobe and pdfalto outputs.\n",
    "    It groups related files or folders in the directory by the stem of their PDF filename.\n",
    "    \n",
    "    E.g. directory structure: \n",
    "    ```\n",
    "    - cclw-1055-bf17ca3b41b943fe83f0bd5c5ff36823_0\n",
    "        - structuredData.json\n",
    "    - cclw-1055-bf17ca3b41b943fe83f0bd5c5ff36823_1\n",
    "        - structuredData.json\n",
    "        - tables/\n",
    "    - cclw-1055-bf17ca3b41b943fe83f0bd5c5ff36823_2\n",
    "        - structuredData.json\n",
    "    - cclw-8482-7a59b4bc5d7841cd9d8a0010215c97ec_metadata.xml\n",
    "    - cclw-8482-7a59b4bc5d7841cd9d8a0010215c97ec_outline.xml\n",
    "    - cclw-8482-7a59b4bc5d7841cd9d8a0010215c97ec.xml\n",
    "    ```\n",
    "    \n",
    "    output:\n",
    "    ```\n",
    "    {\n",
    "        \"cclw-1055-bf17ca3b41b943fe83f0bd5c5ff36823\": [\n",
    "            \"cclw-1055-bf17ca3b41b943fe83f0bd5c5ff36823_0\",\n",
    "            \"cclw-1055-bf17ca3b41b943fe83f0bd5c5ff36823_1\",\n",
    "            \"cclw-1055-bf17ca3b41b943fe83f0bd5c5ff36823_2\",\n",
    "        ],\n",
    "        \"cclw-8482-7a59b4bc5d7841cd9d8a0010215c97ec\": [\n",
    "            \"cclw-8482-7a59b4bc5d7841cd9d8a0010215c97ec_metadata.xml\",\n",
    "            \"cclw-8482-7a59b4bc5d7841cd9d8a0010215c97ec_outline.xml\",\n",
    "            \"cclw-8482-7a59b4bc5d7841cd9d8a0010215c97ec.xml\"\n",
    "        ]\n",
    "    }\n",
    "    ```\n",
    "    \"\"\"\n",
    "    pdf_intermediate_mapping = dict()\n",
    "\n",
    "    pdf_stems = list(set([p.stem.split(\"_\")[0] for p in INTERMEDIATE_FOLDER.iterdir()]))\n",
    "\n",
    "    for pdf_stem in pdf_stems:\n",
    "        pdf_intermediate_mapping[pdf_stem] = sorted([p for p in INTERMEDIATE_FOLDER.iterdir() if str(p.name).startswith(pdf_stem)])\n",
    "        \n",
    "    return pdf_intermediate_mapping\n",
    "\n",
    "pdf_intermediate_mapping = group_intermediate_dir_by_pdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf37ec9e-1d30-4a69-ab0d-b78dd6b416b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                          | 678/940 [09:29<06:30,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS ?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 940/940 [13:15<00:00,  1.18it/s]\n"
     ]
    }
   ],
   "source": [
    "def parse_adobe_folders(folders: List[Path], pdf_filename: str) -> Document:\n",
    "    \"\"\"Parse list of adobe folders into one Document object.\"\"\"\n",
    "    pages = []\n",
    "    # Folders are sorted here to ensure the correct order in parsing\n",
    "    json_paths = [p / \"structuredData.json\" for p in sorted(folders)]\n",
    "    curr_page_offset = 0\n",
    "    \n",
    "    for _path in json_paths:\n",
    "        temp_doc = adobe_extractor.data_to_document(\n",
    "            data_path=_path, \n",
    "            pdf_filename=pdf_filename,\n",
    "            page_offset=curr_page_offset,\n",
    "        )\n",
    "\n",
    "        pages += temp_doc.pages\n",
    "        if pages:\n",
    "            curr_page_offset = pages[-1].page_id + 1\n",
    "        \n",
    "    return Document(\n",
    "        pages=pages,\n",
    "        filename=pdf_filename,\n",
    "    )\n",
    "\n",
    "# ----------------------------\n",
    "\n",
    "pdf_document_objects = dict()\n",
    "\n",
    "for pdf_stem, related_paths in tqdm(pdf_intermediate_mapping.items()):\n",
    "    try:\n",
    "        if all([p.is_dir() for p in related_paths]):\n",
    "            document = parse_adobe_folders(related_paths, pdf_stem)\n",
    "            pdf_document_objects[pdf_stem] = document\n",
    "\n",
    "        elif valid_paths := [p for p in related_paths if p.name == f\"{pdf_stem}.xml\"]:\n",
    "            # Finding the correctly named XML file could also mean that folders are \n",
    "            # present, but these are from Adobe failures\n",
    "            if len(valid_paths) == 1:\n",
    "                document = embedded_extractor.data_to_document(data_path=valid_paths[0], pdf_filename=pdf_stem)\n",
    "                pdf_document_objects[pdf_stem] = document\n",
    "            else:\n",
    "                print(f\"Too many paths for {pdf_stem}\")\n",
    "        else:\n",
    "            # TODO: handle adobe split failures which have fallen back to embedded text extractor\n",
    "            print(pdf_stem, \"?\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed for {pdf_stem}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b982d521-36d4-41fa-885b-1c98c3fa7dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that all PDFs have produced a Document object - list should be empty\n",
    "[k for k,v in pdf_document_objects.items() if not v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0edaa16-ff5a-44eb-a8c5-971a6b1f7ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 939/939 [01:39<00:00,  9.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# Serialise results to JSON and txt\n",
    "for pdf_stem, document in tqdm(pdf_document_objects.items()):\n",
    "    document.save_json(OUTPUT_FOLDER / f\"{pdf_stem}.json\")\n",
    "    document.save_text(OUTPUT_FOLDER / f\"{pdf_stem}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145be768-32f3-493e-8548-f11b6fc677f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
