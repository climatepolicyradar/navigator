{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import re\n",
    "from typing import List, Tuple, Set\n",
    "from collections import defaultdict\n",
    "\n",
    "from extract.document import TextBlock, Page, Document\n",
    "from extract.extract import DocumentTextExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"temp-adobe.json\", \"r\") as f:\n",
    "    data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['//Document/Figure',\n",
       " '//Document/P',\n",
       " '//Document/Figure[2]',\n",
       " '//Document/Aside/P',\n",
       " '//Document/Aside/P[2]',\n",
       " '//Document/Aside/P[3]',\n",
       " '//Document/Aside/P[4]',\n",
       " '//Document/Aside/P[5]',\n",
       " '//Document/P[2]',\n",
       " '//Document/P[3]',\n",
       " '//Document/P[4]',\n",
       " '//Document/P[5]',\n",
       " '//Document/P[6]',\n",
       " '//Document/P[7]',\n",
       " '//Document/Aside[2]/P',\n",
       " '//Document/Aside[2]/P[2]',\n",
       " '//Document/Aside[2]/P[3]',\n",
       " '//Document/Aside[2]/P[4]',\n",
       " '//Document/Figure[3]',\n",
       " '//Document/Aside[3]/P',\n",
       " '//Document/Aside[3]/P[2]',\n",
       " '//Document/H1',\n",
       " '//Document/P[8]',\n",
       " '//Document/P[9]',\n",
       " '//Document/P[10]',\n",
       " '//Document/P[11]',\n",
       " '//Document/P[12]',\n",
       " '//Document/P[13]',\n",
       " '//Document/P[14]',\n",
       " '//Document/Figure[4]',\n",
       " '//Document/P[15]',\n",
       " '//Document/H1[2]',\n",
       " '//Document/P[16]',\n",
       " '//Document/P[17]',\n",
       " '//Document/H1[3]',\n",
       " '//Document/P[18]',\n",
       " '//Document/P[19]',\n",
       " '//Document/P[20]',\n",
       " '//Document/P[21]',\n",
       " '//Document/P[22]',\n",
       " '//Document/P[23]',\n",
       " '//Document/P[24]',\n",
       " '//Document/H1[4]',\n",
       " '//Document/Figure[5]',\n",
       " '//Document/TOC/TOCI/Reference/Span',\n",
       " '//Document/TOC/TOCI[2]/Reference/Span',\n",
       " '//Document/TOC/TOCI[2]/Reference/Span[2]',\n",
       " '//Document/TOC/TOCI[3]/Reference/Span',\n",
       " '//Document/TOC/TOCI[3]/Reference/Span[2]',\n",
       " '//Document/TOC/TOCI[4]/Reference/Span',\n",
       " '//Document/TOC/TOCI[4]/Reference/Span[2]',\n",
       " '//Document/TOC/TOCI[5]/Reference/Span',\n",
       " '//Document/TOC/TOCI[5]/Reference/Span[2]',\n",
       " '//Document/TOC/TOCI[6]/Reference/Span',\n",
       " '//Document/TOC/TOCI[6]/Reference/Span[2]',\n",
       " '//Document/TOC/TOCI[7]/Reference/Span',\n",
       " '//Document/TOC/TOCI[7]/Reference/Span[2]',\n",
       " '//Document/TOC/TOCI[8]/Reference/Span',\n",
       " '//Document/TOC/TOCI[8]/Reference/Span[2]',\n",
       " '//Document/TOC/TOCI[9]/Reference/Span',\n",
       " '//Document/TOC/TOCI[9]/Reference/Span[2]',\n",
       " '//Document/TOC/TOCI[10]/Reference/Span',\n",
       " '//Document/TOC/TOCI[10]/Reference/Span[2]',\n",
       " '//Document/TOC/TOCI[11]/Reference/Span',\n",
       " '//Document/TOC/TOCI[11]/Reference/Span[2]',\n",
       " '//Document/TOC/TOCI[12]/Reference/Span',\n",
       " '//Document/TOC/TOCI[12]/Reference/Span[2]',\n",
       " '//Document/TOC/TOCI[13]/Reference/Span',\n",
       " '//Document/TOC/TOCI[13]/Reference/Span[2]',\n",
       " '//Document/TOC/TOCI[14]/Reference/Span',\n",
       " '//Document/TOC/TOCI[14]/Reference/Span[2]',\n",
       " '//Document/TOC/TOCI[15]/Reference/Span',\n",
       " '//Document/TOC/TOCI[15]/Reference/Span[2]',\n",
       " '//Document/TOC/TOCI[16]/Reference/Span',\n",
       " '//Document/TOC/TOCI[16]/Reference/Span[2]',\n",
       " '//Document/TOC/TOCI[17]/Reference/Span',\n",
       " '//Document/TOC/TOCI[17]/Reference/Span[2]',\n",
       " '//Document/TOC/TOCI[18]/Reference/Span',\n",
       " '//Document/TOC/TOCI[18]/Reference/Span[2]',\n",
       " '//Document/TOC/TOCI[19]/Reference/Span',\n",
       " '//Document/TOC/TOCI[19]/Reference/Span[2]',\n",
       " '//Document/TOC/TOCI[20]/Reference/Span',\n",
       " '//Document/TOC/TOCI[21]/Reference/Span',\n",
       " '//Document/TOC/TOCI[22]/Reference/Span',\n",
       " '//Document/TOC/TOCI[23]/Reference/Span',\n",
       " '//Document/TOC/TOCI[24]/Reference/Span',\n",
       " '//Document/TOC/TOCI[25]/Reference/Span',\n",
       " '//Document/P[25]',\n",
       " '//Document/Figure[6]',\n",
       " '//Document/H1[5]',\n",
       " '//Document/P[26]',\n",
       " '//Document/P[27]',\n",
       " '//Document/P[28]',\n",
       " '//Document/P[29]',\n",
       " '//Document/P[30]',\n",
       " '//Document/P[31]',\n",
       " '//Document/P[32]',\n",
       " '//Document/P[33]',\n",
       " '//Document/P[34]',\n",
       " '//Document/P[35]',\n",
       " '//Document/P[36]',\n",
       " '//Document/P[37]',\n",
       " '//Document/P[38]',\n",
       " '//Document/P[39]',\n",
       " '//Document/P[40]',\n",
       " '//Document/P[41]',\n",
       " '//Document/P[42]',\n",
       " '//Document/P[43]',\n",
       " '//Document/P[44]',\n",
       " '//Document/P[45]',\n",
       " '//Document/P[46]',\n",
       " '//Document/H1[6]',\n",
       " '//Document/H2',\n",
       " '//Document/P[47]',\n",
       " '//Document/P[48]',\n",
       " '//Document/L',\n",
       " '//Document/P[49]',\n",
       " '//Document/L[2]',\n",
       " '//Document/P[50]',\n",
       " '//Document/L[3]',\n",
       " '//Document/Figure[7]',\n",
       " '//Document/P[51]',\n",
       " '//Document/H1[7]',\n",
       " '//Document/H1[8]',\n",
       " '//Document/L[4]',\n",
       " '//Document/Footnote',\n",
       " '//Document/Footnote[2]']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[el[\"Path\"] for el in data['elements']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdobeAPIExtractor(DocumentTextExtractor):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._elements_exclude = [\n",
    "            \"Aside\",\n",
    "            \"Figure\",\n",
    "            \"Footnote\",\n",
    "            \"Reference\",\n",
    "            \"TOC\",\n",
    "            \"Watermark\",\n",
    "            \"Table\",\n",
    "        ]\n",
    "        # Maximum clockwise or anti-clockwise rotation a text element can have, otherwise it's excluded from the parsing results.\n",
    "        self._max_rotation_degrees = 20\n",
    "\n",
    "    @staticmethod\n",
    "    def _flatten_data(data: dict) -> dict:\n",
    "        \"\"\"Flatten out 'Kids' elements which refer to PDF structure.\"\"\"\n",
    "        new_data = {k:v for k,v in data.items() if k != \"elements\"}\n",
    "        new_data[\"elements\"] = []\n",
    "        \n",
    "        for el in data[\"elements\"]:\n",
    "            if \"Kids\" in el:\n",
    "                # We take all the properties of the parent and pass them \n",
    "                # to the each kid, but the kid can overwrite any properties\n",
    "                #Â passed to it by the parent (e.g. bounding boxes).\n",
    "                # This enables propagating page numbers, language prediction\n",
    "                # and other properties to the kids.\n",
    "                parent = {k:v for k,v in el.items() if k != \"Kids\"}\n",
    "                for kid in el[\"Kids\"]:\n",
    "                    new_kid = parent.copy()\n",
    "                    new_kid.update(kid)\n",
    "                    new_data[\"elements\"].append(kid)\n",
    "            else:\n",
    "                new_data[\"elements\"].append(el)\n",
    "        \n",
    "        return new_data\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_lines(char_bounds) -> List[Tuple[float, float]]:\n",
    "        \"\"\"Get and merge lines.\n",
    "\n",
    "        Args:\n",
    "            char_bounds (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get lines as ymin and ymax coordinates of each character bounds\n",
    "        lines = [list(x) for x in set([(i[1], i[3]) for i in char_bounds])]\n",
    "        lines.sort(key=lambda interval: interval[0])\n",
    "        \n",
    "        # Merge overlapping lines\n",
    "        merged = [lines[0]]\n",
    "        for current in lines:\n",
    "            previous = merged[-1]\n",
    "            if current[0] <= previous[1]:\n",
    "                previous[1] = max(previous[1], current[1])\n",
    "            else:\n",
    "                merged.append(current)\n",
    "        \n",
    "        return merged\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_line_number_of_char_bound(char_bound, lines):\n",
    "        in_line_bool_array = [char_bound[1] >= line[0] and char_bound[3] <= line[1] for line in lines]\n",
    "        line_number_list = [idx for idx, val in enumerate(in_line_bool_array) if val]\n",
    "        \n",
    "        if len(line_number_list) != 1:\n",
    "            raise Exception\n",
    "        \n",
    "        return line_number_list[0]\n",
    "\n",
    "    \n",
    "    def _element_to_text_block(self, el: dict, block_id: str) -> TextBlock:\n",
    "        char_bounds = el['CharBounds']\n",
    "        merged_lines = self._get_lines(char_bounds)\n",
    "        chars_in_lines_idxs = [self._get_line_number_of_char_bound(char_bound, merged_lines) for char_bound in char_bounds]\n",
    "        line_change_idxs = [0] + [i for i in range(1,len(chars_in_lines_idxs)) if chars_in_lines_idxs[i]!=chars_in_lines_idxs[i-1]] + [len(el['Text'])]\n",
    "        text_by_line = [el['Text'][line_change_idxs[idx]: line_change_idxs[idx+1]].strip() for idx in range(len(line_change_idxs)-1)]\n",
    "        \n",
    "        return TextBlock(\n",
    "            text=text_by_line,\n",
    "            text_block_id=block_id,\n",
    "            coords=self._convert_coordinate_axis(el['Bounds'], el['Page']),\n",
    "            type=self._structure_path(el[\"Path\"], remove_numbers=True)[-1],\n",
    "            path=self._structure_path(el[\"Path\"], remove_numbers=False)\n",
    "        )\n",
    "    \n",
    "    def _convert_coordinate_axis(self, coords: List[float], page_number: int) -> List[float]:\n",
    "        \"\"\"Convert coordinates so that the origin is at top left, rather than bottom left output by Adobe.\n",
    "\n",
    "        Args:\n",
    "            data: JSON data output by Adobe API.\n",
    "            coords: list of coordinates output by Adobe: [x0, y0, x1, y1] with origin at bottom left.\n",
    "            page_number: number of page output by Adobe. Indexed at 0.\n",
    "        \"\"\"\n",
    "        page_height = self._current_data['pages'][page_number]['height']\n",
    "        \n",
    "        # To reverse the coordinate system we subtract y0 and y1 from the page height and swap\n",
    "        # them.\n",
    "        return [coords[0], page_height-coords[3], coords[2], page_height-coords[1]]\n",
    "    \n",
    "    @staticmethod\n",
    "    def _structure_path(path: str, remove_numbers: bool = True) -> List[str]:\n",
    "        \"\"\"\n",
    "        Convert a PDF path into a list. \n",
    "        E.g. '//Document/Aside[3]/P[2]' becomes['Document', 'Aside', 'P'].\n",
    "        \"\"\"\n",
    "        \n",
    "        path_split = path[2:].split(\"/\")\n",
    "        \n",
    "        if not remove_numbers:\n",
    "            return path_split\n",
    "        else:\n",
    "            return [re.sub(r\"\\[\\d+\\]\", \"\", i) for i in path_split]\n",
    "    \n",
    "    @staticmethod    \n",
    "    def _index_of(val, in_list):\n",
    "        try:\n",
    "            return in_list.index(val)\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "    def _convert_data(self, data: dict, filename: str) -> Document:\n",
    "        page_id = 0\n",
    "        block_counter = 1\n",
    "        text_blocks_by_page = defaultdict(list)\n",
    "        self._current_data = self._flatten_data(data)\n",
    "\n",
    "        for el in self._current_data['elements']:\n",
    "            # Ignore rotated text elements\n",
    "            element_rotation = el.get(\"Rotation\", 0)\n",
    "            if self._max_rotation_degrees < element_rotation < 360-self._max_rotation_degrees:\n",
    "                continue \n",
    "            \n",
    "            # Ignore superscript\n",
    "            if el.get(\"attributes\", {}).get(\"TextPosition\") == \"Sup\":\n",
    "                continue\n",
    "                \n",
    "            # TODO: handle subscript\n",
    "            \n",
    "            if el[\"Page\"] != page_id:\n",
    "                page_id += 1\n",
    "                block_counter = 1\n",
    "            \n",
    "            if not any([e in self._structure_path(el[\"Path\"]) for e in self._elements_exclude]):\n",
    "                block_id = f\"p{page_id}_b{block_counter}\"\n",
    "                \n",
    "                # Ignore blocks without any text which haven't already been excluded by type\n",
    "                if \"Text\" in el:\n",
    "                    text_blocks_by_page[page_id].append(\n",
    "                        self._element_to_text_block(el, block_id)\n",
    "                    )\n",
    "\n",
    "                block_counter += 1\n",
    "        \n",
    "        pages = []    \n",
    "        \n",
    "        for page_id, page_text_blocks in text_blocks_by_page.items():\n",
    "            pages.append(\n",
    "                Page(\n",
    "                    text_blocks=page_text_blocks,\n",
    "                    page_id=page_id,\n",
    "                    dimensions=(data['pages'][page_id]['width'], data['pages'][page_id]['height']),\n",
    "                )\n",
    "            )    \n",
    "            \n",
    "        document = Document(\n",
    "            pages=pages,\n",
    "            filename=filename,\n",
    "        )\n",
    "                                    \n",
    "        return document\n",
    "\n",
    "extractor = AdobeAPIExtractor()\n",
    "\n",
    "doc = extractor._convert_data(data, filename=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be87749a6255d252ad040378f43002f723c0e34b87f0a00235195982ff14862e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
